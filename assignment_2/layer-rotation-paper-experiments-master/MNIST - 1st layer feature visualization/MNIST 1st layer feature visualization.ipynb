{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result computation and analysis of MNIST toy experiment. Goal is to see on a toy example how layer rotation affects the features learned by a network.\n",
    "\n",
    "\n",
    "Experiment info:\n",
    "\n",
    "1 layer MLP (784 hidden) + batchnorm (batchnorm was used to enable larger layer rotations)  \n",
    "reduced MNIST dataset (1000 samples per class) (to increase overparametrization)  \n",
    "Layca as optimization algorithm  \n",
    "different initial learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "\n",
    "import math as m\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "# Force reload of layca_optimizers to pick up fixes\n",
    "import importlib\n",
    "if 'layca_optimizers' in sys.modules:\n",
    "    importlib.reload(sys.modules['layca_optimizers'])\n",
    "from layca_optimizers import SGD\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from experiment_utils import plot_history, history_todict\n",
    "from layer_rotation_utils import LayerRotationCurves, plot_layer_rotation_curves\n",
    "from experiment_utils import lr_schedule\n",
    "\n",
    "from feature_visualization import visualize_1stlayer_weights\n",
    "from utils import load_reduced_mnist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utilities for storing the results in pickle files\n",
    "result_file = 'results.p'\n",
    "def load_results():\n",
    "    if not os.path.isfile(result_file):\n",
    "        return {}\n",
    "    else:\n",
    "        with open(result_file,'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "def dump_results(results):\n",
    "    with open(result_file,'wb') as f:\n",
    "        pickle.dump(dict(results),f)\n",
    "\n",
    "def update_results(path, new_data):\n",
    "    results = load_results()\n",
    "    position = results\n",
    "    for p in path:\n",
    "        position = position[p]\n",
    "    # new_data is a dictionary with the new (key,value) pairs\n",
    "    position.update(new_data)\n",
    "    dump_results(results)\n",
    "    \n",
    "# if results should be saved in the file or not\n",
    "save_results = True\n",
    "if not save_results:\n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# smaller dataset to get overparametrized model\n",
    "x_train, y_train, x_test, y_test = load_reduced_mnist_data(samples_per_class = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp = Input((784,))\n",
    "    x = Dense(784, activation = 'linear', name = 'dense0')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(10, activation = 'softmax', name = 'densef')(x)\n",
    "    return Model(inp,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configuration of the different learning rate schedules \n",
    "# (a division of the learning rate by 5 is used to escape plateaus in the loss curve)\n",
    "training_configs = {3**-2: (100, LearningRateScheduler(lr_schedule(3**-2,1./5.,[90]))),\n",
    "                    3**-2.5: (100, LearningRateScheduler(lr_schedule(3**-2.5,1./5.,[95]))),\n",
    "                    3**-3: (100, LearningRateScheduler(lr_schedule(3**-3,1./5.,[95]))),\n",
    "                    3**-4: (100, LearningRateScheduler(lr_schedule(3**-4,1.,[np.inf]))),\n",
    "                    3**-5: (120, LearningRateScheduler(lr_schedule(3**-5,1.,[np.inf]))),\n",
    "                    3**-6: (300, LearningRateScheduler(lr_schedule(3**-6,1.,[np.inf]))),\n",
    "                    3**-7: (1000, LearningRateScheduler(lr_schedule(3**-7,1.,[np.inf])))}\n",
    "\n",
    "lrs = [3**-2,3**-2.5,3**-3,3**-4]\n",
    "for lr in lrs:\n",
    "    model = get_model()\n",
    "\n",
    "    weights_location = 'saved_weights/mnist_initial_weights.weights.h5'\n",
    "    if not os.path.isfile(weights_location):\n",
    "        model.save_weights(weights_location)\n",
    "    else:\n",
    "        model.load_weights(weights_location)\n",
    "\n",
    "    epochs = training_configs[lr][0]\n",
    "    lr_sched = training_configs[lr][1]\n",
    "\n",
    "    ladc = LayerRotationCurves(batch_frequency = np.inf)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr,layca = True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=2048,\n",
    "                        epochs=epochs,\n",
    "                        verbose=0,\n",
    "                        validation_data = (x_test,y_test),\n",
    "                        callbacks = [ladc, lr_sched])\n",
    "\n",
    "\n",
    "    if save_results:\n",
    "        update_results([],{lr:{'history':history_todict(history),'ladc':ladc.memory}})\n",
    "    else:\n",
    "        results.update({lr:{'history':history_todict(history),'ladc':ladc.memory}})\n",
    "\n",
    "    if save_results:\n",
    "        model.save_weights('saved_weights/'+str(round(lr,6))[2:]+'.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_aspect(ax=None):  # used to compute rotation of text here under\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    fig = ax.figure\n",
    "\n",
    "    ll, ur = ax.get_position() * fig.get_size_inches()\n",
    "    width, height = ur - ll\n",
    "    axes_ratio = height / width\n",
    "    aspect = axes_ratio / ax.get_data_ratio()\n",
    "\n",
    "    return aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpld3.disable_notebook()\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "lrs = [3**-2,3**-2.5,3**-3,3**-4]\n",
    "lrs_text = ['lr = $3^{-2}$', 'lr = $3^{-2.5}$', 'lr = $3^{-3}$', 'lr = $3^{-4}$']\n",
    "\n",
    "results = load_results()\n",
    "plt.figure()\n",
    "plt.ylim([0,1])\n",
    "plt.xlim([0,100])\n",
    "\n",
    "for i,lr in enumerate(lrs):\n",
    "    ladc_dense0 = np.array(results[lr]['ladc'])[:,0]\n",
    "    \n",
    "    plt.plot(range(len(ladc_dense0)),ladc_dense0)\n",
    "    \n",
    "    x_coord = 50+5*i\n",
    "    diff = 30\n",
    "    angle = m.atan((ladc_dense0[x_coord+diff]-ladc_dense0[x_coord])/diff*get_aspect())*180/m.pi\n",
    "    \n",
    "    plt.annotate(lrs_text[i], xy=(x_coord, ladc_dense0[x_coord]), xycoords='data', color = 'C'+str(i), size = 20,\n",
    "                 rotation = angle+5, rotation_mode='anchor',\n",
    "                 xytext = (0,5), textcoords = 'offset points')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cosine distance')\n",
    "\n",
    "plt.savefig('figures/mnist_layer_rotations.png',format='png', dpi=200, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666000008583069, 0.9670000076293945, 0.9642999768257141, 0.9567999839782715]\n",
      "\n",
      "[1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "lrs = [3**-2,3**-2.5,3**-3,3**-4]\n",
    "\n",
    "results = load_results()\n",
    "test_performances = []\n",
    "train_performances = []\n",
    "for lr in lrs:\n",
    "    # Handle both old and new metric names for compatibility\n",
    "    if 'val_acc' in results[lr]['history']['history']:\n",
    "        test_performances.append(results[lr]['history']['history']['val_acc'][-1])\n",
    "        train_performances.append(results[lr]['history']['history']['acc'][-1])\n",
    "    else:\n",
    "        test_performances.append(results[lr]['history']['history']['val_accuracy'][-1])\n",
    "        train_performances.append(results[lr]['history']['history']['accuracy'][-1])\n",
    "print(test_performances)\n",
    "print()\n",
    "print(train_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [3**-2,3**-2.5,3**-3,3**-4]\n",
    "\n",
    "results = load_results()\n",
    "model = get_model()\n",
    "\n",
    "mpld3.disable_notebook()\n",
    "nb_neurons = 5\n",
    "neurons_per_line = nb_neurons\n",
    "f, axes = plt.subplots(len(lrs), nb_neurons, \n",
    "                       figsize = (nb_neurons*3,len(lrs)*3))\n",
    "for i,lr in enumerate(lrs):\n",
    "    model.load_weights('saved_weights/'+str(round(lr,6))[2:]+'.weights.h5')\n",
    "    \n",
    "    weights = model.get_weights()[0]\n",
    "    visualize_1stlayer_weights(weights,nb_neurons = nb_neurons, neuron_indices = range(5,10),\n",
    "                               neurons_per_line = neurons_per_line, axes = axes[i])\n",
    "    \n",
    "    # Handle both old and new metric names for compatibility\n",
    "    if 'val_acc' in results[lr]['history']['history']:\n",
    "        train_acc = results[lr]['history']['history']['acc'][-1]\n",
    "        val_acc = results[lr]['history']['history']['val_acc'][-1]\n",
    "    else:\n",
    "        train_acc = results[lr]['history']['history']['accuracy'][-1]\n",
    "        val_acc = results[lr]['history']['history']['val_accuracy'][-1]\n",
    "    \n",
    "    pad = -160\n",
    "    axes[i,-1].annotate(' Train: '+str(round(train_acc*100,2))+'%'+\n",
    "                        '\\n Test: '+str(round(val_acc*100,2))+'%', \n",
    "                        xy=(0., 0.5), xytext=(-axes[i,-1].yaxis.labelpad - pad, 0.), \n",
    "                xycoords=axes[i,-1].yaxis.label, textcoords='offset points', \n",
    "                size=25, ha='left', va='center',rotation=0)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "plt.subplots_adjust(hspace=-0.3)\n",
    "\n",
    "plt.savefig('figures/mnist_features_visualization.png',format='png', dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "f, axes = plt.subplots(1, nb_neurons, \n",
    "                       figsize = (nb_neurons*3,3))\n",
    "    \n",
    "model.load_weights('saved_weights/mnist_initial_weights.weights.h5')\n",
    "weights = model.get_weights()[0]\n",
    "visualize_1stlayer_weights(weights,nb_neurons = nb_neurons, neuron_indices = range(5,10),\n",
    "                           neurons_per_line = neurons_per_line, axes = axes)\n",
    "\n",
    "pad = 10\n",
    "axes[0].annotate('initialization', xy=(0, 0.5), xytext=(-axes[0].yaxis.labelpad - pad, 0),\n",
    "            xycoords=axes[0].yaxis.label, textcoords='offset points',\n",
    "            size=25, ha='right', va='center',rotation=90)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "# plt.subplots_adjust(hspace=-0.3)\n",
    "plt.savefig('figures/mnist_initialization_visualization.png',format='png', dpi=200, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
